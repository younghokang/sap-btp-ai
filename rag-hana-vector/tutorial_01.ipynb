{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c76108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting generative-ai-hub-sdk[all]\n",
      "  Using cached generative_ai_hub_sdk-4.10.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting overloading==0.5.0 (from generative-ai-hub-sdk[all])\n",
      "  Using cached overloading-0.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from generative-ai-hub-sdk[all]) (25.0)\n",
      "Collecting openai>=1.58.1 (from generative-ai-hub-sdk[all])\n",
      "  Downloading openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ai-core-sdk>=2.5.7 (from generative-ai-hub-sdk[all])\n",
      "  Using cached ai_core_sdk-2.5.7-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting dacite>=1.8.1 (from generative-ai-hub-sdk[all])\n",
      "  Using cached dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting click>=8.1.7 (from generative-ai-hub-sdk[all])\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx>=0.27.0 (from generative-ai-hub-sdk[all])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic==2.10.6 (from generative-ai-hub-sdk[all])\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting boto3==1.37.0 (from generative-ai-hub-sdk[all])\n",
      "  Using cached boto3-1.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting langchain-aws==0.2.15 (from generative-ai-hub-sdk[all])\n",
      "  Using cached langchain_aws-0.2.15-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting google-cloud-aiplatform==1.83.0 (from generative-ai-hub-sdk[all])\n",
      "  Using cached google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting aioboto3==14.1.0 (from generative-ai-hub-sdk[all])\n",
      "  Using cached aioboto3-14.1.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting langchain~=0.3.0 (from generative-ai-hub-sdk[all])\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community~=0.3.0 (from generative-ai-hub-sdk[all])\n",
      "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-google-vertexai==2.0.15 (from generative-ai-hub-sdk[all])\n",
      "  Using cached langchain_google_vertexai-2.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting langchain-openai>=0.3.7 (from generative-ai-hub-sdk[all])\n",
      "  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting aiobotocore==2.21.1 (from aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached aiobotocore-2.21.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting aiofiles>=23.2.1 (from aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.0 (from boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached botocore-1.37.38-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached s3transfer-0.11.5-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Downloading google_api_core-2.25.0rc0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_cloud_bigquery-3.31.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached shapely-2.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.27 (from langchain-aws==0.2.15->generative-ai-hub-sdk[all])\n",
      "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy<3,>=1.26.0 (from langchain-aws==0.2.15->generative-ai-hub-sdk[all])\n",
      "  Using cached numpy-2.2.5-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai==2.0.15->generative-ai-hub-sdk[all])\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic==2.10.6->generative-ai-hub-sdk[all])\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6->generative-ai-hub-sdk[all])\n",
      "  Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.2 (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Downloading aiohttp-3.11.18-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.0 (from boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached botocore-1.37.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all]) (2.9.0.post0)\n",
      "Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached multidict-6.4.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting ai-api-client-sdk==2.4.6 (from ai-core-sdk>=2.5.7->generative-ai-hub-sdk[all])\n",
      "  Using cached ai_api_client_sdk-2.4.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting aenum~=3.1 (from ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk[all])\n",
      "  Using cached aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyhumps~=3.0 (from ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk[all])\n",
      "  Using cached pyhumps-3.8.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting requests<3.0 (from ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk[all])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->generative-ai-hub-sdk[all])\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx>=0.27.0->generative-ai-hub-sdk[all])\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->generative-ai-hub-sdk[all])\n",
      "  Using cached httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.27.0->generative-ai-hub-sdk[all])\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->generative-ai-hub-sdk[all])\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Downloading langsmith-0.3.33-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached sqlalchemy-2.0.40-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai>=0.3.7->generative-ai-hub-sdk[all])\n",
      "  Using cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.58.1->generative-ai-hub-sdk[all])\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.58.1->generative-ai-hub-sdk[all])\n",
      "  Using cached jiter-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai>=1.58.1->generative-ai-hub-sdk[all])\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai>=1.58.1->generative-ai-hub-sdk[all])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached frozenlist-1.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.9.2->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all])\n",
      "  Using cached yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (72 kB)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore<1.38.0,>=1.37.0->boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0.0,>=2.0.0 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0,>=0.14.0 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached google_crc32c-1.7.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.27->langchain-aws==0.2.15->generative-ai-hub-sdk[all])\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=23.2 (from generative-ai-hub-sdk[all])\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached orjson-3.10.16-cp313-cp313-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0->ai-api-client-sdk==2.4.6->ai-core-sdk>=2.5.7->generative-ai-hub-sdk[all])\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "INFO: pip is looking at multiple versions of s3transfer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3==1.37.0->generative-ai-hub-sdk[all])\n",
      "  Using cached s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached s3transfer-0.11.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai>=0.3.7->generative-ai-hub-sdk[all])\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-aws==0.2.15->generative-ai-hub-sdk[all])\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.83.0->generative-ai-hub-sdk[all])\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore==2.21.1->aiobotocore[boto3]==2.21.1->aioboto3==14.1.0->generative-ai-hub-sdk[all]) (1.17.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community~=0.3.0->generative-ai-hub-sdk[all])\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached aioboto3-14.1.0-py3-none-any.whl (35 kB)\n",
      "Using cached boto3-1.37.0-py3-none-any.whl (139 kB)\n",
      "Using cached google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl (7.3 MB)\n",
      "Using cached langchain_aws-0.2.15-py3-none-any.whl (109 kB)\n",
      "Using cached langchain_google_vertexai-2.0.15-py3-none-any.whl (95 kB)\n",
      "Using cached overloading-0.5.0-py3-none-any.whl (10 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached aiobotocore-2.21.1-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached ai_core_sdk-2.5.7-py3-none-any.whl (153 kB)\n",
      "Using cached ai_api_client_sdk-2.4.6-py3-none-any.whl (265 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached dacite-1.9.2-py3-none-any.whl (16 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
      "Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached generative_ai_hub_sdk-4.10.2-py3-none-any.whl (611 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading aiohttp-3.11.18-cp313-cp313-macosx_11_0_arm64.whl (454 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached botocore-1.37.1-py3-none-any.whl (13.4 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.25.0rc0-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Using cached google_cloud_bigquery-3.31.0-py3-none-any.whl (250 kB)\n",
      "Using cached google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)\n",
      "Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jiter-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.33-py3-none-any.whl (358 kB)\n",
      "Using cached numpy-2.2.5-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached s3transfer-0.11.3-py3-none-any.whl (84 kB)\n",
      "Using cached shapely-2.1.0-cp313-cp313-macosx_11_0_arm64.whl (1.6 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached sqlalchemy-2.0.40-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl (195 kB)\n",
      "Using cached frozenlist-1.6.0-cp313-cp313-macosx_11_0_arm64.whl (120 kB)\n",
      "Using cached google_cloud_core-2.4.3-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_crc32c-1.7.1-cp313-cp313-macosx_12_0_arm64.whl (30 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.4.3-cp313-cp313-macosx_11_0_arm64.whl (36 kB)\n",
      "Using cached orjson-3.10.16-cp313-cp313-macosx_15_0_arm64.whl (133 kB)\n",
      "Using cached propcache-0.3.1-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached pyhumps-3.8.0-py3-none-any.whl (6.1 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Using cached wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached yarl-1.20.0-cp313-cp313-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pyhumps, overloading, aenum, zstandard, wrapt, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pyasn1, protobuf, propcache, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, jmespath, jiter, idna, httpx-sse, h11, grpcio, google-crc32c, frozenlist, docstring-parser, distro, dacite, click, charset-normalizer, certifi, cachetools, attrs, annotated-types, aioitertools, aiohappyeyeballs, aiofiles, yarl, typing-inspection, typing-inspect, SQLAlchemy, shapely, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, marshmallow, jsonpatch, httpcore, googleapis-common-protos, google-resumable-media, botocore, anyio, aiosignal, tiktoken, s3transfer, requests-toolbelt, pydantic, httpx, grpcio-status, google-auth, dataclasses-json, aiohttp, ai-api-client-sdk, pydantic-settings, openai, langsmith, grpc-google-iam-v1, google-api-core, boto3, aiobotocore, ai-core-sdk, langchain-core, google-cloud-core, generative-ai-hub-sdk, langchain-text-splitters, langchain-openai, langchain-aws, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, aioboto3, langchain, google-cloud-aiplatform, langchain-google-vertexai, langchain-community\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 aenum-3.1.15 ai-api-client-sdk-2.4.6 ai-core-sdk-2.5.7 aioboto3-14.1.0 aiobotocore-2.21.1 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aioitertools-0.12.0 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 boto3-1.37.0 botocore-1.37.1 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 dacite-1.9.2 dataclasses-json-0.6.7 distro-1.9.0 docstring-parser-0.16 frozenlist-1.6.0 generative-ai-hub-sdk-4.10.2 google-api-core-2.25.0rc0 google-auth-2.39.0 google-cloud-aiplatform-1.83.0 google-cloud-bigquery-3.31.0 google-cloud-core-2.4.3 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 grpc-google-iam-v1-0.14.2 grpcio-1.71.0 grpcio-status-1.71.0 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jiter-0.9.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.24 langchain-aws-0.2.15 langchain-community-0.3.22 langchain-core-0.3.55 langchain-google-vertexai-2.0.15 langchain-openai-0.3.14 langchain-text-splitters-0.3.8 langsmith-0.3.33 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 numpy-2.2.5 openai-1.76.0 orjson-3.10.16 overloading-0.5.0 packaging-24.2 propcache-0.3.1 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.9.1 pyhumps-3.8.0 python-dotenv-1.1.0 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9.1 s3transfer-0.11.3 shapely-2.1.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspect-0.9.0 typing-inspection-0.4.0 urllib3-2.4.0 wrapt-1.17.2 yarl-1.20.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade \"generative-ai-hub-sdk[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbef00a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# please enter the Credentials from your AI core landscape.\n",
    "env_vars = {\n",
    "    'AICORE_AUTH_URL' : 'https://ai-dev-2025-jypl7lq7.authentication.us21.hana.ondemand.com',\n",
    "    'AICORE_CLIENT_ID' : 'sb-cb3e467a-adbc-4d9d-ae6b-a4c62441c6d7!b33974|xsuaa_std!b22746',\n",
    "    'AICORE_CLIENT_SECRET' : '5339fb21-1cc8-45cf-996a-ee87982f66dc$wYOmtC9o6S9ypdCwwiJR4Cr_uKysaO9c9sl_xvWLhfk=',\n",
    "    'AICORE_BASE_URL' : 'https://api.ai.prod-us21.eastus.azure.ml.hana.ondemand.com/v2',\n",
    "    'AICORE_RESOURCE_GROUP' : 'new-resource-group'\n",
    "}\n",
    "\n",
    "# Set the environment variables using `os.environ`.\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39672cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'L1', 'L2', 'L3', 'FILENAME', 'HEADER1', 'HEADER2', 'TEXT', 'VECTOR_STR']\n"
     ]
    }
   ],
   "source": [
    "# Read data from 'GRAPH_DOCU_2503.csv' and store each row in the 'data' list\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "with open('GRAPH_DOCU_2503.csv', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            data.append(row)\n",
    "        except:\n",
    "            print(row)\n",
    "\n",
    "print(data[0])  # Print the first row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e51d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a secure connection to an SAP HANA database using hdbcli \n",
    "# pip install hdbcli\n",
    "import hdbcli\n",
    "from hdbcli import dbapi\n",
    "\n",
    "cc = dbapi.connect(\n",
    "    address='7a1c2ce7-c54f-4137-b298-f7e93e1f50e5.hana.prod-us21.hanacloud.ondemand.com',\n",
    "    port='443',\n",
    "    user='DEVELOPER',\n",
    "    password='Bticto25!',\n",
    "    encrypt=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf6f611a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(288, 'cannot use duplicate table name: TABLENAME_AI: line 1 col 14 (at pos 13)')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m cursor = cc.cursor()\n\u001b[32m      3\u001b[39m sql_command = \u001b[33m'''\u001b[39m\u001b[33mCREATE TABLE TABLENAME_AI(ID1 BIGINT, ID2 BIGINT, L1 NVARCHAR(3), L2 NVARCHAR(3), L3 NVARCHAR(3), FILENAME NVARCHAR(100), HEADER1 NVARCHAR(5000), HEADER2 NVARCHAR(5000), TEXT NCLOB, VECTOR_STR REAL_VECTOR);\u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_command\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m cursor.close()\n",
      "\u001b[31mProgrammingError\u001b[39m: (288, 'cannot use duplicate table name: TABLENAME_AI: line 1 col 14 (at pos 13)')"
     ]
    }
   ],
   "source": [
    "# Create a table\n",
    "cursor = cc.cursor()\n",
    "sql_command = '''CREATE TABLE TABLENAME_AI(ID1 BIGINT, ID2 BIGINT, L1 NVARCHAR(3), L2 NVARCHAR(3), L3 NVARCHAR(3), FILENAME NVARCHAR(100), HEADER1 NVARCHAR(5000), HEADER2 NVARCHAR(5000), TEXT NCLOB, VECTOR_STR REAL_VECTOR);'''\n",
    "cursor.execute(sql_command)\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc44df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting data into the specified table using a prepared SQL statement with real vector conversion.\n",
    "cursor = cc.cursor()\n",
    "sql_insert = 'INSERT INTO TABLENAME_AI(ID1, ID2, L1, L2, L3, FILENAME, HEADER1, HEADER2, TEXT, VECTOR_STR) VALUES (?,?,?,?,?,?,?,?,?,TO_REAL_VECTOR(?))'\n",
    "cursor.executemany(sql_insert,data[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37fb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hana_ml\n",
      "  Using cached hana_ml-2.24.25040300-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hdbcli>=2.18.22 (from hana_ml)\n",
      "  Using cached hdbcli-2.24.24-cp38-abi3-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Collecting pydotplus (from hana_ml)\n",
      "  Using cached pydotplus-2.0.2-py3-none-any.whl\n",
      "Collecting Deprecated (from hana_ml)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from hana_ml) (4.67.1)\n",
      "Collecting schedule (from hana_ml)\n",
      "  Using cached schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting prettytable (from hana_ml)\n",
      "  Using cached prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: shapely>=1.8.1 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from hana_ml) (2.1.0)\n",
      "Collecting plotly>=4.14.3 (from hana_ml)\n",
      "  Using cached plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from hana_ml) (2.2.5)\n",
      "Collecting pandas>=0.24.2 (from hana_ml)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting jinja2>=3.0.0 (from hana_ml)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=3.0.0->hana_ml)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from pandas>=0.24.2->hana_ml) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.24.2->hana_ml)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.24.2->hana_ml)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly>=4.14.3->hana_ml)\n",
      "  Downloading narwhals-1.36.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: packaging in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from plotly>=4.14.3->hana_ml) (24.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from Deprecated->hana_ml) (1.17.2)\n",
      "Requirement already satisfied: wcwidth in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from prettytable->hana_ml) (0.2.13)\n",
      "Collecting pyparsing>=2.0.1 (from pydotplus->hana_ml)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/a58241/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->hana_ml) (1.17.0)\n",
      "Using cached hana_ml-2.24.25040300-py3-none-any.whl (9.0 MB)\n",
      "Using cached hdbcli-2.24.24-cp38-abi3-macosx_11_0_arm64.whl (5.0 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Using cached schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading narwhals-1.36.0-py3-none-any.whl (331 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, hdbcli, tzdata, schedule, pyparsing, prettytable, narwhals, MarkupSafe, Deprecated, pydotplus, plotly, pandas, jinja2, hana_ml\n",
      "Successfully installed Deprecated-1.2.18 MarkupSafe-3.0.2 hana_ml-2.24.25040300 hdbcli-2.24.24 jinja2-3.1.6 narwhals-1.36.0 pandas-2.2.3 plotly-6.0.1 prettytable-3.16.0 pydotplus-2.0.2 pyparsing-3.2.3 pytz-2025.2 schedule-1.2.2 tzdata-2025.2\n",
      "2.24.25040300\n",
      "base_url=None auth_url=None client_id=None client_secret=None resource_group=None ai_core_client=<ai_core_sdk.ai_core_v2_client.AICoreV2Client object at 0x116c27380>\n"
     ]
    }
   ],
   "source": [
    "! pip install hana_ml\n",
    "import hana_ml\n",
    "print(hana_ml.__version__)\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "proxy_client = get_proxy_client('gen-ai-hub') # for an AI Core proxy\n",
    "\n",
    "print(proxy_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ac71dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No deployment found with: deployment.model_name == text-embedding-ada-002",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m     response = embeddings.create(\n\u001b[32m      6\u001b[39m       model_name=model,\n\u001b[32m      7\u001b[39m       \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m\n\u001b[32m      8\u001b[39m     )\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.data[\u001b[32m0\u001b[39m].embedding\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHello world!\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Example usage of the get_embedding function\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(input, model)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(\u001b[38;5;28minput\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-ada-002\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.data[\u001b[32m0\u001b[39m].embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages/gen_ai_hub/proxy/native/openai/clients.py:89\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, deployment_id, model_name, config_id, config_name, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m model_name = if_set(model_name, if_set(model))\n\u001b[32m     83\u001b[39m model_identification = kwargs_if_set(\n\u001b[32m     84\u001b[39m     deployment_id=deployment_id,\n\u001b[32m     85\u001b[39m     model_name=model_name,\n\u001b[32m     86\u001b[39m     config_id=config_id,\n\u001b[32m     87\u001b[39m     config_name=config_name,\n\u001b[32m     88\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m deployment = \u001b[43mproxy_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_identification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m model_name = deployment.model_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m???\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_deployment(deployment):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/sap_btp/sap-btp-ai/.venv/lib/python3.13/site-packages/gen_ai_hub/proxy/gen_ai_hub_proxy/client.py:237\u001b[39m, in \u001b[36mGenAIHubProxyClient.select_deployment\u001b[39m\u001b[34m(self, raise_on_multiple, **search_key_value)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m matched_deployments[\u001b[32m0\u001b[39m]\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mNo deployment found with: \u001b[39m\u001b[33m'\u001b[39m + \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\n\u001b[32m    238\u001b[39m         [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdeployment.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m search_key_value.items()]\n\u001b[32m    239\u001b[39m     ))\n",
      "\u001b[31mValueError\u001b[39m: No deployment found with: deployment.model_name == text-embedding-ada-002"
     ]
    }
   ],
   "source": [
    "# Get embeddings\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "def get_embedding(input, model=\"text-embedding-ada-002\") -> str:\n",
    "    response = embeddings.create(\n",
    "      model_name=model,\n",
    "      input=input\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "get_embedding('Hello world!')  # Example usage of the get_embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad4c4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a vector search on the table using the specified metric and return the top k results\n",
    "cursor = cc.cursor()\n",
    "def run_vector_search(query: str, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    if metric == 'L2DISTANCE':\n",
    "        sort = 'ASC'\n",
    "    else:\n",
    "        sort = 'DESC'\n",
    "    query_vector = get_embedding(query)\n",
    "    sql = '''SELECT TOP {k} \"ID2\", \"TEXT\"\n",
    "        FROM \"TABLENAME_AI\"\n",
    "        ORDER BY \"{metric}\"(\"VECTOR_STR\", TO_REAL_VECTOR('{qv}')) {sort}'''.format(k=k, metric=metric, qv=query_vector, sort=sort)\n",
    "    cursor.execute(sql)\n",
    "    hdf = cursor.fetchall()\n",
    "    return hdf[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef5cca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template\n",
    "promptTemplate_fstring = \"\"\"\n",
    "You are an SAP HANA Cloud expert.\n",
    "You are provided multiple context items that are related to the prompt you have to answer.\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{query}\n",
    "\"\"\"\n",
    "from langchain.prompts import PromptTemplate\n",
    "promptTemplate = PromptTemplate.from_template(promptTemplate_fstring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e18dbc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gen_ai_hub.proxy.langchain.openai.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules, and define a function to query an LLM with a formatted prompt and vector-based context\n",
    "# pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "print(ChatOpenAI)\n",
    "\n",
    "def retrieve_and_query_llm(query: str, metric='COSINE_SIMILARITY', k = 4) -> str:\n",
    "    context = ''\n",
    "    context = run_vector_search(query, metric, k)\n",
    "    prompt = promptTemplate.format(query=query, context=' '.join(str(context)))\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = len(encoding.encode(str(prompt)))\n",
    "    print('no of tokens'+ str(num_tokens))\n",
    "    llm = ChatOpenAI(proxy_model_name='gpt-4-32k',max_tokens = 8000)\n",
    "    response = llm.invoke(prompt).content\n",
    "    print('Query: '+ query)\n",
    "    print('\\nResponse:')\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c3402d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No deployment found with: deployment.model_name == text-embedding-ada-002",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Query the LLM with a request about calculating the shortest path and retrieve the response\u001b[39;00m\n\u001b[32m      3\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mI want to calculate a shortest path. How do I do that?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mretrieve_and_query_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m response\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mretrieve_and_query_llm\u001b[39m\u001b[34m(query, metric, k)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_and_query_llm\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, metric=\u001b[33m'\u001b[39m\u001b[33mCOSINE_SIMILARITY\u001b[39m\u001b[33m'\u001b[39m, k = \u001b[32m4\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      9\u001b[39m     context = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     context = \u001b[43mrun_vector_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     prompt = promptTemplate.format(query=query, context=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(context)))\n\u001b[32m     12\u001b[39m     encoding = tiktoken.get_encoding(\u001b[33m\"\u001b[39m\u001b[33mcl100k_base\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mrun_vector_search\u001b[39m\u001b[34m(query, metric, k)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      7\u001b[39m     sort = \u001b[33m'\u001b[39m\u001b[33mDESC\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m query_vector = \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m sql = \u001b[33m'''\u001b[39m\u001b[33mSELECT TOP \u001b[39m\u001b[38;5;132;01m{k}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mID2\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTEXT\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m    FROM \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTABLENAME_AI\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m    ORDER BY \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{metric}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mVECTOR_STR\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, TO_REAL_VECTOR(\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{qv}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)) \u001b[39m\u001b[38;5;132;01m{sort}\u001b[39;00m\u001b[33m'''\u001b[39m.format(k=k, metric=metric, qv=query_vector, sort=sort)\n\u001b[32m     12\u001b[39m cursor.execute(sql)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mget_embedding\u001b[39m\u001b[34m(input, model)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_embedding\u001b[39m(\u001b[38;5;28minput\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-ada-002\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.data[\u001b[32m0\u001b[39m].embedding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/gen_ai_hub/proxy/native/openai/clients.py:89\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, deployment_id, model_name, config_id, config_name, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m model_name = if_set(model_name, if_set(model))\n\u001b[32m     83\u001b[39m model_identification = kwargs_if_set(\n\u001b[32m     84\u001b[39m     deployment_id=deployment_id,\n\u001b[32m     85\u001b[39m     model_name=model_name,\n\u001b[32m     86\u001b[39m     config_id=config_id,\n\u001b[32m     87\u001b[39m     config_name=config_name,\n\u001b[32m     88\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m deployment = \u001b[43mproxy_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_identification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m model_name = deployment.model_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m???\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_deployment(deployment):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/gen_ai_hub/proxy/gen_ai_hub_proxy/client.py:237\u001b[39m, in \u001b[36mGenAIHubProxyClient.select_deployment\u001b[39m\u001b[34m(self, raise_on_multiple, **search_key_value)\u001b[39m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m matched_deployments[\u001b[32m0\u001b[39m]\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mNo deployment found with: \u001b[39m\u001b[33m'\u001b[39m + \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\n\u001b[32m    238\u001b[39m         [\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mdeployment.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m search_key_value.items()]\n\u001b[32m    239\u001b[39m     ))\n",
      "\u001b[31mValueError\u001b[39m: No deployment found with: deployment.model_name == text-embedding-ada-002"
     ]
    }
   ],
   "source": [
    "# Query the LLM with a request about calculating the shortest path and retrieve the response\n",
    "\n",
    "query = \"I want to calculate a shortest path. How do I do that?\"\n",
    "response = retrieve_and_query_llm(query=query, k=4)\n",
    "response\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
